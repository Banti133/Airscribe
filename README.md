# Airscribe
Novel and interactive application for creating digital art using hand gestures in mid-air. This project leverages computer vision techniques, specifically hand tracking and gesture recognition, to translate user movements into drawing actions on a virtual canvas.

AirScribe projects typically involve the following components and techniques:
Hand Tracking: Hand tracking algorithms are used to detect and track the movement of the user's hand or finger. This can be done using computer vision libraries like Open-CV or machine learning frameworks like Media-pipe.
Gesture Recognition: Gesture recognition algorithms are employed to interpret the user's hand gestures and translate them into specific actions, such as drawing, erasing, or changing colors.
Virtual Canvas: A virtual canvas is created where the user's drawings or writings are displayed. This can be a computer screen, a projection, or even a virtual reality headset.
Drawing Implementation: The user's hand movements are mapped to digital strokes on the virtual canvas, allowing them to draw or write in mid-air.

<img width="456" alt="image" src="https://github.com/Banti133/Airscribe/assets/134291468/50dc27e6-6337-46bc-b968-79d7620b5e8c">

Identify Requirements:
Hardware: Camera with good resolution and frame rate, computer with processing power for image processing.
Software: Programming language (Python with OpenCV is popular), libraries for computer vision and user interface development.
Technical Skills: Understanding of computer vision, image processing, and user interface design.
